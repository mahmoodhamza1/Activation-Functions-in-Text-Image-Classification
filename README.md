# Activation-Functions-in-Text-Image-Classification
This project investigates the performance of three widely used activation functions — ReLU, Leaky ReLU, and Swish — in deep learning models for text classification and image classification tasks.
